import os
import io
import logging
import requests

from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters
)
import openai

# ==== –ö–õ–Æ–ß–Ü ====
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# ==== –õ–û–ì–ò ====
logging.basicConfig(level=logging.INFO)

# ==== –°–ò–°–¢–ï–ú–ù–ò–ô –ü–†–û–ú–ü–¢ (–¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π) ====
SYSTEM_PROMPT = (
    "–¢–∏ ‚Äî –ø–æ–º—ñ—á–Ω–∏–∫ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —á–∞—Ç—É Vibe-Coding. "
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, —á–µ–º–Ω–æ —Ç–∞ –ª–∞–∫–æ–Ω—ñ—á–Ω–æ. "
    "–ú–æ–∂–Ω–∞ –ª–µ–≥–∫–∞ —ñ—Ä–æ–Ω—ñ—è –ø—Ä–æ —Ç–∏–ø–æ–≤—ñ '–±–æ–ª—ñ' –ø—Ä–æ–≥—Ä–∞–º—ñ—Å—Ç—ñ–≤, –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—ñ."
)

# ==== –î–û–ü–û–ú–û–ì–ê/–ü–†–ê–í–ò–õ–ê ====
HELP_TEXT = (
    "–ö–æ–º–∞–Ω–¥–∏:\n"
    "/img <–æ–ø–∏—Å> ‚Äî –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—é (–æ–±–æ–≤'—è–∑–∫–æ–≤–æ –ø–æ—á–∏–Ω–∞–π –∑ /img)\n"
    "/help ‚Äî –¥–æ–ø–æ–º–æ–≥–∞"
)

# ==== –£–¢–ò–õ–Ü–¢–ò –î–õ–Ø –ó–û–ë–†–ê–ñ–ï–ù–¨ ====
def _download_to_bytes(url: str) -> bytes:
    r = requests.get(url, timeout=45)
    r.raise_for_status()
    return r.content

def _image_create_url(prompt: str) -> tuple[str, str]:
    """
    –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ gpt-image-1 (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞ —É —Ç–≤–æ—î–º—É –∞–∫–∞—É–Ω—Ç—ñ/API-—à–ª—é–∑—ñ),
    —è–∫—â–æ –ø–∞–¥–∞—î ‚Äî –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –Ω–∞ dall-e-3.
    –ü–æ–≤–µ—Ä—Ç–∞—î (url, model_name).
    """
    # 1) gpt-image-1
    try:
        resp = openai.Image.create(
            model="gpt-image-1",
            prompt=prompt,
            size="1024x1024",
            n=1
        )
        return resp["data"][0]["url"], resp.get("model", "gpt-image-1")
    except Exception as e:
        logging.warning("gpt-image-1 failed: %s ‚Äî falling back to dall-e-3", e)

    # 2) dall-e-3 (—Å—Ç–∞–±—ñ–ª—å–Ω–æ –∑ openai==0.28.0)
    resp = openai.Image.create(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        n=1
    )
    return resp["data"][0]["url"], resp.get("model", "dall-e-3")

# ==== –ö–û–ú–ê–ù–î–ò ====
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤—ñ—Ç! –î–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π: /img <–æ–ø–∏—Å>. –î–ª—è –¥–æ–≤—ñ–¥–∫–∏: /help")

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(HELP_TEXT)

async def img_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = " ".join(context.args).strip()
    if not prompt:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –æ–ø–∏—Å: /img <—â–æ –Ω–∞–º–∞–ª—é–≤–∞—Ç–∏>\n–ü—Ä–∏–∫–ª–∞–¥: /img –∫—ñ—Ç —É –º—É–ª—å—Ç—è—à–Ω–æ–º—É —Å—Ç–∏–ª—ñ")
        return

    try:
        url, model_used = _image_create_url(prompt)
        img_bytes = _download_to_bytes(url)
        bio = io.BytesIO(img_bytes); bio.name = "image.png"; bio.seek(0)
        await update.message.reply_photo(bio, caption=f"–ì–æ—Ç–æ–≤–æ ‚úÖ")
        logging.info("Image OK | model=%s | prompt='%s'", model_used, prompt)
    except Exception as e:
        logging.exception("Image gen error: %s", e)
        await update.message.reply_text("–ù–µ –≤–∏–π—à–ª–æ —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è üòï –°–ø—Ä–æ–±—É–π —ñ–Ω—à–∏–π –æ–ø–∏—Å (–¥–æ–¥–∞–π ¬´–º—É–ª—å—Ç—è—à–Ω–∏–π —Å—Ç–∏–ª—å¬ª).")

# ==== –¢–ï–ö–°–¢–û–í–Ü –ü–û–í–Ü–î–û–ú–õ–ï–ù–ù–Ø ====
async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return
    text = update.message.text.strip()

    # –¢–†–ò–ì–ï–†–ò: —Ç–µ–≥ –∞–±–æ –ø–æ—á–∞—Ç–æ–∫ –∑—ñ —Å–ª–æ–≤–∞ "–±–æ—Ç"
    bot_username = (context.bot.username or "").lower()
    entities = update.message.entities or []
    mentioned_bot = any(
        e.type == "mention" and
        text[e.offset:e.offset + e.length].lower() == f"@{bot_username}"
        for e in entities
    )
    starts_with_word = text.lower().startswith("–±–æ—Ç")
    if not (mentioned_bot or starts_with_word):
        return

    try:
        completion = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": text}
            ],
            temperature=0.4
        )
        reply = completion["choices"][0]["message"]["content"].strip()
        await update.message.reply_text(reply)
        usage = completion.get("usage", {})
        logging.info("Chat OK | model=%s | prompt=%s | completion=%s",
                     completion.get("model"), usage.get("prompt_tokens"), usage.get("completion_tokens"))
    except Exception as e:
        logging.exception("Text gen error: %s", e)
        await update.message.reply_text("–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ñ –®–Ü. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑ üôè")

# ==== –û–ë–†–û–ë–ö–ê –ü–û–ú–ò–õ–û–ö ====
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE):
    logging.exception("Bot error: %s", context.error)

# ==== –ó–ê–ü–£–°–ö ====
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("img", img_cmd))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))
    app.add_error_handler(on_error)
    app.run_polling(drop_pending_updates=True, allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
