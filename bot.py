import logging
import os
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import openai

# üîë Keys
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

logging.basicConfig(level=logging.INFO)

SYSTEM_PROMPT = (
    "–¢–∏ ‚Äî –æ—Ñ—ñ—Ü—ñ–π–Ω–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —á–∞—Ç—É Vibe-Coding. "
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, —á–µ–º–Ω–æ —ñ –ø–æ —Å—É—Ç—ñ, –∑ –ª–µ–≥–∫–æ—é —ñ—Ä–æ–Ω—ñ—î—é –ø—Ä–æ —Ç–∏–ø–æ–≤—ñ –±–æ–ª—ñ –ø—Ä–æ–≥—Ä–∞–º—ñ—Å—Ç—ñ–≤ (–±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—ñ). "
    "–ù–µ –¥–æ–ø—É—Å–∫–∞–π –º–æ–≤–∏ –Ω–µ–Ω–∞–≤–∏—Å—Ç—ñ —á–∏ –∑–∞–∫–ª–∏–∫—ñ–≤ –¥–æ –Ω–∞—Å–∏–ª—å—Å—Ç–≤–∞. "
    "–Ø–∫—â–æ –ø—Ä–æ—Å—è—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Äî –ø—Ä–∏–π–º–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å —ñ –≥–µ–Ω–µ—Ä—É–π —ó—ó."
)

HELP_TEXT = (
    "üëã –Ø–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—å –±–æ—Ç–æ–º:\n"
    "‚Ä¢ –ó–≤–µ—Ä—Ç–∞–π—Å—è —Ç–µ–≥–æ–º @—ñ–º º—è_–±–æ—Ç–∞ –∞–±–æ –ø–æ—á–∏–Ω–∞–π –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑—ñ —Å–ª–æ–≤–∞ ¬´–±–æ—Ç¬ª.\n"
    "‚Ä¢ –©–æ–± –Ω–∞–º–∞–ª—é–≤–∞—Ç–∏: /img <–æ–ø–∏—Å> –∞–±–æ ¬´–∑–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É <–æ–ø–∏—Å>¬ª, ¬´–Ω–∞–º–∞–ª—é–π <–æ–ø–∏—Å>¬ª.\n"
    "–ü—Ä–∏–∫–ª–∞–¥: /img –ª–æ–≥–æ —É —Å—Ç–∏–ª—ñ –º—ñ–Ω—ñ–º–∞–ª—ñ–∑–º, —Å–∏–Ω—å–æ-–∂–æ–≤—Ç—ñ –∫–æ–ª—å–æ—Ä–∏.\n"
)

RULES_TEXT = (
    "–ü—Ä–∞–≤–∏–ª–∞ Vibe-Coding: –ø–æ–≤–∞–≥–∞, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤, —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞. "
    "–ë–µ–∑ –º–æ–≤–∏ –Ω–µ–Ω–∞–≤–∏—Å—Ç—ñ —Ç–∞ –ø—Ä–æ–ø–∞–≥–∞–Ω–¥–∏ –∞–≥—Ä–µ—Å—ñ—ó. –î–æ–ø–æ–º–∞–≥–∞—î–º–æ –æ–¥–Ω–µ –æ–¥–Ω–æ–º—É, –¥—ñ–ª–∏–º–æ—Å—å —ñ–¥–µ—è–º–∏ —Ç–∞ –∫–æ–¥–æ–º."
)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤—ñ—Ç! –Ø GPT-–±–æ—Ç Vibe-Coding. –ù–∞–ø–∏—à–∏ ¬´–±–æ—Ç ...¬ª –∞–±–æ —Ç–µ–≥–Ω–∏ @–º–µ–Ω–µ. –î–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫: /img <–æ–ø–∏—Å>."
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(HELP_TEXT)

async def rules_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(RULES_TEXT)

async def generate_image_and_reply(update: Update, prompt: str):
    try:
        # OpenAI Images API (–¥–ª—è openai==0.28 ‚Äî Image.create)
        img_resp = openai.Image.create(
            model="gpt-image-1",
            prompt=prompt,
            size="1024x1024"
        )
        url = img_resp["data"][0]["url"]
        await update.message.reply_photo(url, caption="–ì–æ—Ç–æ–≤–æ ‚úÖ")
    except Exception as e:
        logging.exception("Image gen error: %s", e)
        await update.message.reply_text("–ù–µ –≤–∏–π—à–ª–æ —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è üòï –°–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –æ–ø–∏—Å.")

async def img_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = " ".join(context.args).strip()
    if not prompt:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –æ–ø–∏—Å: /img <—â–æ –Ω–∞–º–∞–ª—é–≤–∞—Ç–∏>")
        return
    await generate_image_and_reply(update, prompt)

def is_image_request(text: str) -> bool:
    t = text.lower().strip()
    return t.startswith("–∑–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É") or t.startswith("–Ω–∞–º–∞–ª—é–π") or t.startswith("—Å—Ç–≤–æ—Ä–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É")

async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return
    user_message = update.message.text.strip()

    # –¢—Ä–∏–≥–µ—Ä: —Ç–µ–≥ —Å–∞–º–µ –Ω–∞—à–æ–≥–æ –±–æ—Ç–∞ –∞–±–æ –ø–æ—á–∞—Ç–æ–∫ "–±–æ—Ç"
    bot_username = (context.bot.username or "").lower()
    entities = update.message.entities or []
    mentioned_bot = any(
        e.type == "mention" and
        user_message[e.offset:e.offset + e.length].lower() == f"@{bot_username}"
        for e in entities
    )
    starts_with_word = user_message.lower().startswith("–±–æ—Ç")

    if not (mentioned_bot or starts_with_word or is_image_request(user_message)):
        return

    # –Ø–∫—â–æ –ø—Ä–æ—Å–∏–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Äî –≥–µ–Ω–µ—Ä—É—î–º–æ —ñ –≤–∏—Ö–æ–¥–∏–º–æ
    if is_image_request(user_message):
        # –≤–∏—Ä—ñ–∑–∞—î–º–æ –∫–ª—é—á–æ–≤–µ —Å–ª–æ–≤–æ —ñ –ª–∏—à–∞—î–º–æ –æ–ø–∏—Å
        for kw in ["–∑–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "–Ω–∞–º–∞–ª—é–π", "—Å—Ç–≤–æ—Ä–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É"]:
            if user_message.lower().startswith(kw):
                prompt = user_message[len(kw):].strip(" :,-")
                break
        if not prompt:
            await update.message.reply_text("–î–æ–¥–∞–π –æ–ø–∏—Å –¥–æ –∑–∞–ø–∏—Ç—É –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É üôÇ")
            return
        await generate_image_and_reply(update, prompt)
        return

    # –Ü–Ω–∞–∫—à–µ ‚Äî –∑–≤–∏—á–∞–π–Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    try:
        completion = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_message}
            ],
            temperature=0.4,
        )
        reply = completion["choices"][0]["message"]["content"].strip()
        await update.message.reply_text(reply)
        # (–Ω–µ–æ–±–æ–≤‚Äô—è–∑–∫–æ–≤–æ) –∑–∞–ª–æ–≥—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å —ñ —Ç–æ–∫–µ–Ω–∏
        usage = completion.get("usage", {})
        logging.info("OpenAI model=%s prompt=%s completion=%s",
                     completion.get("model"), usage.get("prompt_tokens"), usage.get("completion_tokens"))
    except Exception as e:
        logging.exception("OpenAI error: %s", e)
        await update.message.reply_text("–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ñ –®–Ü. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑ üôè")

def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("rules", rules_cmd))
    app.add_handler(CommandHandler("img", img_cmd))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))
    app.run_polling(drop_pending_updates=True, allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
