import os
import io
import base64
import logging
import re

from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters
)
import openai

# ====== –ö–õ–Æ–ß–Ü ===============================================================
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# ====== –õ–û–ì–ò ================================================================
logging.basicConfig(level=logging.INFO)

# ====== –°–ò–°–¢–ï–ú–ù–ò–ô –ü–†–û–ú–ü–¢ ====================================================
SYSTEM_PROMPT = (
    "–¢–∏ ‚Äî –æ—Ñ—ñ—Ü—ñ–π–Ω–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —á–∞—Ç—É Vibe-Coding. "
    "–ú–µ—Ç–∞ —Å–ø—ñ–ª—å–Ω–æ—Ç–∏: –≤–∞–π–±-–∫–æ–¥–∏–Ω–≥ ‚Äî —ñ–¥–µ—ó —Ñ–æ—Ä–º—É–ª—é—î –ª—é–¥–∏–Ω–∞, –∫–æ–¥ –ø–∏—à–µ –®–Ü. "
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é, —á–µ–º–Ω–æ, –ª–∞–∫–æ–Ω—ñ—á–Ω–æ —ñ –ø–æ —Å—É—Ç—ñ. –î–æ–∑–≤–æ–ª–µ–Ω–∞ –ª–µ–≥–∫–∞ —ñ—Ä–æ–Ω—ñ—è "
    "—â–æ–¥–æ —Ç–∏–ø–æ–≤–∏—Ö ¬´–±–æ–ª–µ–π¬ª –ø—Ä–æ–≥—Ä–∞–º—ñ—Å—Ç—ñ–≤ –±–µ–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—ñ. "
    "–ù–µ –¥–æ–ø—É—Å–∫–∞–π –º–æ–≤–∏ –Ω–µ–Ω–∞–≤–∏—Å—Ç—ñ —á–∏ –∑–∞–∫–ª–∏–∫—ñ–≤ –¥–æ –Ω–∞—Å–∏–ª—å—Å—Ç–≤–∞. "
    "–Ø–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –ø—Ä–æ—Å–∏—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚Äî –ø—Ä–∏–π–º–∏ –æ–ø–∏—Å —ñ —Å—Ç–≤–æ—Ä–∏ —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—é. "
    "–í —Ä–∞–∑—ñ –ø–æ—Ä—É—à–µ–Ω—å ‚Äî –≤–≤—ñ—á–ª–∏–≤–æ –≤—ñ–¥–º–æ–≤–ª—è–π —ñ –ø—Ä–æ–ø–æ–Ω—É–π –±–µ–∑–ø–µ—á–Ω—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É."
)

HELP_TEXT = (
    "üëã –Ø–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—å –±–æ—Ç–æ–º:\n"
    "‚Ä¢ –ó–≤–µ—Ä—Ç–∞–π—Å—è —Ç–µ–≥–æ–º @—ñ–º º—è_–±–æ—Ç–∞ –∞–±–æ –ø–æ—á–∏–Ω–∞–π –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑—ñ —Å–ª–æ–≤–∞ ¬´–±–æ—Ç¬ª.\n"
    "‚Ä¢ –°—Ç–≤–æ—Ä–∏—Ç–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É: /img <–æ–ø–∏—Å>\n"
    "  –∞–±–æ —Ñ—Ä–∞–∑–∏: ¬´–∑–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Ä¶¬ª, ¬´–Ω–∞–º–∞–ª—é–π ‚Ä¶¬ª, ¬´—Å—Ç–≤–æ—Ä–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Ä¶¬ª.\n"
    "–ü—Ä–∏–∫–ª–∞–¥: /img –º—ñ–Ω—ñ–º–∞–ª—ñ—Å—Ç–∏—á–Ω–µ –ª–æ–≥–æ —É —Å–∏–Ω—å–æ-–∂–æ–≤—Ç–∏—Ö –∫–æ–ª—å–æ—Ä–∞—Ö."
)

RULES_TEXT = (
    "–ü—Ä–∞–≤–∏–ª–∞ Vibe-Coding: –ø–æ–≤–∞–≥–∞, —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤. "
    "–ë–µ–∑ –º–æ–≤–∏ –Ω–µ–Ω–∞–≤–∏—Å—Ç—ñ, –¥–∏—Å–∫—Ä–∏–º—ñ–Ω–∞—Ü—ñ—ó —Ç–∞ –∑–∞–∫–ª–∏–∫—ñ–≤ –¥–æ –Ω–∞—Å–∏–ª—å—Å—Ç–≤–∞. "
    "–î—ñ–ª–∏–º–æ—Å—å —ñ–¥–µ—è–º–∏, –∫–æ–¥–æ–º —ñ –¥–æ–ø–æ–º–∞–≥–∞—î–º–æ –æ–¥–Ω–µ –æ–¥–Ω–æ–º—É. –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ! üá∫üá¶"
)

# ====== –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á ===================================================

IMAGE_KEYWORDS = (
    "–∑–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "–Ω–∞–º–∞–ª—é–π", "—Å—Ç–≤–æ—Ä–∏ –∫–∞—Ä—Ç–∏–Ω–∫—É", "–≥–µ–Ω–µ—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É",
    "—Å—Ç–≤–æ—Ä–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", "–∑–≥–µ–Ω–µ—Ä—É–π –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"
)

def is_image_request(text: str) -> bool:
    t = (text or "").lower().strip()
    return any(t.startswith(k) for k in IMAGE_KEYWORDS)

# –ü—Ä–æ—Å—Ç–µ ¬´–ø–æ–º‚Äô—è–∫—à–µ–Ω–Ω—è¬ª –ø—Ä–æ–º–ø—Ç—ñ–≤, —â–æ–± —É–Ω–∏–∫–∞—Ç–∏ –≤—ñ–¥–º–æ–≤ –º–æ–¥–µ—Ä–∞—Ü—ñ—ó
SOFTEN_MAP = {
    r"\b–±'?—î—Ç—å—Å—è\b": "–∑–º–∞–≥–∞—î—Ç—å—Å—è",
    r"\b–±–∏—Ç–∏\b": "–∑–º–∞–≥–∞—Ç–∏—Å—è",
    r"\b–±–∏—Ç–≤–∞\b": "–ø–æ—î–¥–∏–Ω–æ–∫",
}
BANNED_REAL_PERSONS = [
    # –Ω–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–±—Ä–∞–∑–ª–∏–≤—ñ –≤–∏—Ä–∞–∑–∏; –ª–∏—à–µ –∫—ñ–ª—å–∫–∞ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ —Ä–µ–∞–ª—å–Ω–∏—Ö –æ—Å—ñ–±/–ø–æ–ª—ñ—Ç–∏–∫—ñ–≤
    "—è–Ω—É–∫–æ–≤–∏—á", "–ø—É—Ç—ñ–Ω", "–∑–µ–ª–µ–Ω—Å—å–∫–∏–π", "—ñ–ª–æ–Ω –º–∞—Å–∫", "–º–∞—Å–∫", "–±–∞–π–¥–µ–Ω", "—Ç—Ä–∞–º–ø"
]

def soften_prompt(p: str) -> str:
    t = p.strip()
    # –ø—Ä–∏–±—Ä–∞—Ç–∏ –∑–≥–∞–¥–∫–∏ —Ä–µ–∞–ª—å–Ω–∏—Ö –æ—Å—ñ–± -> —É–∑–∞–≥–∞–ª—å–Ω–∏—Ç–∏
    low = t.lower()
    if any(name in low for name in BANNED_REAL_PERSONS):
        t = re.sub("|".join(BANNED_REAL_PERSONS), "–≤—ñ–¥–æ–º–∏–π –¥—ñ—è—á (–≤–∏–≥–∞–¥–∞–Ω–∏–π –æ–±—Ä–∞–∑)", t, flags=re.IGNORECASE)
        t += ", –º—É–ª—å—Ç—è—à–Ω–∏–π/–∫–∞—Ä–∏–∫–∞—Ç—É—Ä–Ω–∏–π —Å—Ç–∏–ª—å, –±–µ–∑ —Å—Ö–æ–∂–æ—Å—Ç—ñ –∑ —Ä–µ–∞–ª—å–Ω–æ—é –æ—Å–æ–±–æ—é"
    # –∑–∞–º—ñ–Ω–∏ ¬´–Ω–∞—Å–∏–ª—å–Ω–∏—Ü—å–∫–∏—Ö¬ª —Å–ª—ñ–≤ –Ω–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ñ
    for pat, rep in SOFTEN_MAP.items():
        t = re.sub(pat, rep, t, flags=re.IGNORECASE)
    # –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –ø—ñ–¥–∫–∞–∑–∫–∏ –¥–ª—è —è–∫–æ—Å—Ç—ñ
    if "–º—É–ª—å—Ç—è—à" not in t.lower() and "–∫–∞—Ä–∏–∫–∞—Ç—É—Ä" not in t.lower() and "—ñ–ª—é—Å—Ç—Ä–∞—Ü" not in t.lower():
        t += ", —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—è, –¥—Ä—É–∂–Ω—ñ–π –º—É–ª—å—Ç—è—à–Ω–∏–π —Å—Ç–∏–ª—å"
    return t

# ====== –ö–û–ú–ê–ù–î–ò =============================================================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤—ñ—Ç! –Ø GPT-–±–æ—Ç Vibe-Coding. –ù–∞–ø–∏—à–∏ ¬´–±–æ—Ç ‚Ä¶¬ª –∞–±–æ —Ç–µ–≥–Ω–∏ @–º–µ–Ω–µ. "
        "–î–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω—å —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Å—è /img <–æ–ø–∏—Å>."
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(HELP_TEXT)

async def rules_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(RULES_TEXT)

# ====== –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ó–û–ë–†–ê–ñ–ï–ù–¨ =================================================

async def generate_image_and_reply(update: Update, prompt: str):
    """–ì–µ–Ω–µ—Ä—É—î–º–æ –∫–∞—Ä—Ç–∏–Ω–∫—É —è–∫ base64 —ñ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —ó—ó —è–∫ —Ñ–æ—Ç–æ."""
    try:
        safe_prompt = soften_prompt(prompt)
        img_resp = openai.Image.create(
            model="gpt-image-1",
            prompt=safe_prompt,
            size="1024x1024",
            n=1,
            response_format="b64_json"
        )
        b64 = img_resp["data"][0]["b64_json"]
        img_bytes = base64.b64decode(b64)

        bio = io.BytesIO(img_bytes)
        bio.name = "image.png"
        bio.seek(0)
        await update.message.reply_photo(bio, caption="–ì–æ—Ç–æ–≤–æ ‚úÖ")

        logging.info("Image OK | prompt='%s' | model=%s", safe_prompt, img_resp.get("model", "gpt-image-1"))
    except Exception as e:
        logging.exception("Image gen error: %s", e)
        await update.message.reply_text(
            "–ù–µ –≤–∏–π—à–ª–æ —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è üòï –°–ø—Ä–æ–±—É–π –∫–æ—Ä–æ—Ç—à–∏–π –∞–±–æ –º‚Äô—è–∫—à–∏–π –æ–ø–∏—Å (–º—É–ª—å—Ç—è—à–Ω–∏–π —Å—Ç–∏–ª—å)."
        )

async def img_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = " ".join(context.args).strip()
    if not prompt:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –æ–ø–∏—Å: /img <—â–æ –Ω–∞–º–∞–ª—é–≤–∞—Ç–∏>")
        return
    await generate_image_and_reply(update, prompt)

# ====== –ß–ê–¢-–õ–û–ì–Ü–ö–ê ==========================================================

async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return
    user_message = update.message.text.strip()

    # –¢—Ä–∏–≥–µ—Ä: —Ç–µ–≥ —Å–∞–º–µ –Ω–∞—à–æ–≥–æ –±–æ—Ç–∞ –∞–±–æ –ø–æ—á–∞—Ç–æ–∫ –∑—ñ —Å–ª–æ–≤–∞ "–±–æ—Ç"
    bot_username = (context.bot.username or "").lower()
    entities = update.message.entities or []
    mentioned_bot = any(
        e.type == "mention" and
        user_message[e.offset:e.offset + e.length].lower() == f"@{bot_username}"
        for e in entities
    )
    starts_with_word = user_message.lower().startswith("–±–æ—Ç")

    # –Ø–∫—â–æ —Ü–µ –∑–∞–ø–∏—Ç –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É ‚Äî –Ω–∞–≤—ñ—Ç—å –±–µ–∑ —Ç—Ä–∏–≥–µ—Ä–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î–º–æ
    if is_image_request(user_message):
        # –≤—ñ–¥—Ä—ñ–∑–∞—î–º–æ –∫–ª—é—á–æ–≤–µ —Å–ª–æ–≤–æ —ñ –ª–∏—à–∞—î–º–æ –æ–ø–∏—Å
        lower = user_message.lower()
        for kw in IMAGE_KEYWORDS:
            if lower.startswith(kw):
                prompt = user_message[len(kw):].strip(" :,-")
                break
        else:
            prompt = user_message
        if not prompt:
            await update.message.reply_text("–î–æ–¥–∞–π –æ–ø–∏—Å –¥–æ –∑–∞–ø–∏—Ç—É –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è üôÇ")
            return
        await generate_image_and_reply(update, prompt)
        return

    if not (mentioned_bot or starts_with_word):
        return

    # –¢–µ–∫—Å—Ç–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    try:
        completion = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_message}
            ],
            temperature=0.4,
        )
        reply = completion["choices"][0]["message"]["content"].strip()
        await update.message.reply_text(reply)

        usage = completion.get("usage", {})
        logging.info("Chat OK | model=%s | prompt=%s | completion=%s",
                     completion.get("model"), usage.get("prompt_tokens"), usage.get("completion_tokens"))
    except Exception as e:
        logging.exception("OpenAI error: %s", e)
        await update.message.reply_text("–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è —Ç–∏–º—á–∞—Å–æ–≤–∞ –ø–æ–º–∏–ª–∫–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ñ –®–Ü. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑ üôè")

# ====== –û–ë–†–û–ë–ö–ê –ü–û–ú–ò–õ–û–ö –¢–ì-–ë–Ü–ë–õ–Ü–û–¢–ï–ö–ò ======================================

async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE):
    logging.exception("Bot error: %s", context.error)

# ====== –ó–ê–ü–£–°–ö ==============================================================

def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("rules", rules_cmd))
    app.add_handler(CommandHandler("img", img_cmd))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))
    app.add_error_handler(on_error)
    # drop_pending_updates ‚Äî —â–æ–± –Ω–µ –Ω–∞–≤–∞–ª—é–≤–∞–ª–∏—Å—è —Å—Ç–∞—Ä—ñ –∞–ø–¥–µ–π—Ç–∏ –ø—ñ—Å–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫—É
    app.run_polling(drop_pending_updates=True, allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
